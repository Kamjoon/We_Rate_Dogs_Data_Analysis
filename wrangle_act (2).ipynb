{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from tweepy import OAuthHandler\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "arch_df = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url) \n",
    "with open(os.path.join(url.split('/')[-1]), mode='wb') as file: \n",
    "        file.write(response.content)\n",
    "        \n",
    "images = pd.read_csv('image-predictions.tsv', delimiter = '\\t')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'HIDDEN'\n",
    "consumer_secret = 'HIDDEN'\n",
    "access_token = 'HIDDEN'\n",
    "access_secret = 'HIDDEN'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n",
    "# df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n",
    "# change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n",
    "# NOTE TO REVIEWER: this student had mobile verification issues so the following\n",
    "# Twitter API code was sent to this student from a Udacity instructor\n",
    "# Tweet IDs for which to gather additional data via Twitter's API\n",
    "tweet_ids = arch_df.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "with open('tweet-json.txt', 'r') as json_file:\n",
    "    for line in json_file:\n",
    "        status = json.loads(line)\n",
    "        \n",
    "        # Append to list of dictionaries\n",
    "        df_list.append({'tweet_id': status['id'],\n",
    "                        'retweet_count': status['retweet_count'],\n",
    "                        'favorite_count': status['favorite_count'],\n",
    "                       })\n",
    "\n",
    "# Create a DataFrame with tweet ID, retweet count, favorite count and display_text_range\n",
    "json_tweets = pd.DataFrame(df_list, columns = ['tweet_id', 'favorite_count', 'retweet_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n",
    "programmatic assessement to assess the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets look at a preview of the archived dataframe\n",
    "arch_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets preview the json file dataframe\n",
    "json_tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am checking for any missing data within the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_df.info()\n",
    "json_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am seeing if any of the columns have less than or more than the values they are suuposed to. For instance, the denominator column should only have 10 as a value. While the numerator column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see if there may be any erraneous data in the rating_deominator column. All values should be 10. \n",
    "arch_df.describe().rating_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets take a look to see if there are any duplicated TweetIDs\n",
    "print('archived', sum(arch_df.duplicated('tweet_id')))\n",
    "print('predictions', sum(json_tweets.duplicated('tweet_id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I am comparing the tweet_id columns in both of the data frames to see if there are any missing tweet id's \n",
    "\n",
    "arch_df['tweet_id'].isin(json_tweets['tweet_id']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "\n",
    "1. Erraneous Columns\n",
    "\n",
    "2. Need to delete retweets \n",
    "\n",
    "3. Delete reply tweets \n",
    "\n",
    "4. Erraneous dog names are present such as, 'by' or 'None'. \n",
    "\n",
    "5. Abbreviating Source links\n",
    "\n",
    "6. Filling in all of the none type values with 'None' for more flexibliy \n",
    "\n",
    "7. Some rating demonator values or more or less than 10\n",
    "\n",
    "8. There are tweets without images. They will need to be removed. \n",
    "\n",
    "9. Choose the dog with the highest confidence rating. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1. Merge Dataframes and get rid of unneccesary columns\n",
    "\n",
    "2. The dog stage columns (doggo,floofer,pupper,puppo) can be combined into one column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n",
    "clean_arch = arch_df.copy()\n",
    "clean_json = json_tweets.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy Issue #1: \n",
    "\n",
    "Merge Dataframes and get rid of unneccesary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:  \n",
    "\n",
    "We will be merging all 3 dataframes (clean_json, images, and clean_arch) into one master data frame using the pandas merge function. This will prepare us for cleaning the data later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = clean_json.copy()\n",
    "master_df = pd.merge(clean_arch, images, how = 'left', on = ['tweet_id'] )\n",
    "master_df = pd.merge(master_df, clean_json, how = 'left', on = ['tweet_id'] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2:  \n",
    "\n",
    "We need to combine the 4 dog stages (doggo, floofer, pupper, puppo) into one column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "\n",
    "We will be combining the 4 dog stage columns into one column to make the data tidier. We will be using adding the dog_stage column and adding the values to the column and then dropping the extra columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are confirming the value in the columns\n",
    "print(master_df.doggo.value_counts())\n",
    "print(master_df.floofer.value_counts())\n",
    "print(master_df.pupper.value_counts())\n",
    "print(master_df.puppo.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column \n",
    "master_df.doggo.replace('None', '', inplace = True)\n",
    "master_df.floofer.replace('None', '', inplace = True)\n",
    "master_df.pupper.replace('None', '', inplace = True)\n",
    "master_df.puppo.replace('None', '', inplace = True)\n",
    "\n",
    "\n",
    "master_df['dog_stage'] = master_df['doggo'].astype(str) + master_df[\"floofer\"].astype(str) + master_df[\"pupper\"].astype(str) + master_df[\"puppo\"].astype(str)\n",
    "#Testing\n",
    "master_df.dog_stage.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dog_stage names\n",
    "master_df.loc[master_df.dog_stage=='nannannanpuppo','dog_stage']='Puppo'\n",
    "master_df.loc[master_df.dog_stage=='nannanpuppernan','dog_stage']='Pupper'\n",
    "master_df.loc[master_df.dog_stage=='nanfloofernannan','dog_stage']='Floofer'\n",
    "master_df.loc[master_df.dog_stage=='doggonannannan','dog_stage']='Doggo'\n",
    "master_df.loc[master_df.dog_stage=='nannannannan','dog_stage']='None'\n",
    "master_df.loc[master_df.dog_stage=='doggonanpuppernan','dog_stage']='Unknown'\n",
    "master_df.loc[master_df.dog_stage=='doggonannanpuppo','dog_stage']='Unknown'\n",
    "master_df.loc[master_df.dog_stage=='doggofloofernannan','dog_stage']='Unknown'\n",
    "\n",
    "master_df['dog_stage'].replace('nannannanpuppo','Puppo')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#replace blank cells with unknown\n",
    "master_df.dog_stage.replace('','Unknown', inplace=True)\n",
    "master_df.dog_stage.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extra columns \n",
    "master_df.drop(['doggo','pupper','floofer','puppo'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Delete duplicated tweet_id (retweets)\n",
    "master_df = master_df[pd.isnull(master_df.retweeted_status_id)]\n",
    "#3 Delete tweet replies\n",
    "master_df = master_df[master_df['in_reply_to_status_id'].isna()]\n",
    "#4 Delete tweets without pictures\n",
    "master_df = master_df.dropna(subset = ['jpg_url'])\n",
    "master_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conditions \n",
    "conditions = [(master_df['p1_dog'] == True),(master_df['p2_dog'] == True),(master_df['p3_dog'] == True)]\n",
    "\n",
    "# Create the Choice order\n",
    "choice_breed = [master_df['p1'],master_df['p2'],master_df['p3']]\n",
    "\n",
    "# Create the Choice order based on the confidence interval\n",
    "choices_confidence = [master_df['p1_conf'],master_df['p2_conf'],master_df['p3_conf']]\n",
    "\n",
    "# Select breed based on first successful condition\n",
    "master_df['breed'] = np.select(conditions, choices_breed, default = 'none')\n",
    "\n",
    "# select predicted confidence level based on first successful condition\n",
    "master_df['confidence'] = np.select(conditions, choices_confidence,default = 0)\n",
    "\n",
    "#test\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type for the confidence interval to a whole number\n",
    "master_df.confidence = (master_df.confidence * 100).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete irrelevant columns\n",
    "master_df.drop(['p1', 'p1_dog', 'p1_conf','p2', 'p2_dog', 'p2_conf','p3', 'p3_dog', 'p3_conf','in_reply_to_status_id','in_reply_to_user_id', 'retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp','doggo','floofer','pupper','puppo'], axis = 1, inplace = True)\n",
    "\n",
    "master_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Delete irrelevant columns \n",
    "master_df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Renameing source links\n",
    "\n",
    "#Creating a dictionary that will hold the abbreviated text\n",
    "source_text = {\n",
    "    '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>' : 'Twitter for iPhone',\n",
    "    '<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>' : 'Vine - Make a Scene',\n",
    "    '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>' : 'Twitter Web Client',\n",
    "    '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>' : 'TweetDeck'\n",
    "}\n",
    "\n",
    "# Creating funcation that will replace the keys with values\n",
    "def rename_s(df):\n",
    "    if df['source'] in source_text.keys():\n",
    "        abbrev = source_text[df['source']]\n",
    "        return abbrev\n",
    "    else:\n",
    "        return df['source']\n",
    "    \n",
    "# Calling our function   \n",
    "master_df.source = master_df.apply(rename_s, axis=1)\n",
    "master_df.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Replace all of the nonetype data entries with \"None\"\n",
    "master_df.fillna('None', inplace = True)\n",
    "#Change favorite count data to whole integer\n",
    "master_df.favorite_count = master_df.favorite_count.astype(int)\n",
    "master_df.retweet_count = master_df.retweet_count.astype(int)\n",
    "\n",
    "names_mask = master_df.name.str.contains('^[a-z]', regex = True)\n",
    "\n",
    "master_df[names_mask].name.value_counts().sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets replace these with the \"None\" Value. \n",
    "master_df.loc[names_mask, 'name'] = \"None\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all ratings with values more than 10 or less than 10. \n",
    "\n",
    "rating_mask = master_df.rating_denominator >= 10\n",
    "master_df[rating_mask].rating_denominator.value_counts().sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df[master_df.rating_denominator <= 10]\n",
    "master_df[rating_mask].rating_denominator.value_counts().sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.describe()\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv('twitter_archived_master.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. According to the data we rate dogs rates golden retrieve more than any other breed. \n",
    "2. Which UI source is the most popular? \n",
    "3. There is a strong correlation in the number of retweets and favorites performed by users. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Favorited Pups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.query('dog_stage == None').value_counts()\n",
    "master_df.dog_stage.replace('', 'Unknown', inplace = True)\n",
    "labelz = ['Pupper','Doggo','Puppo','Unknown','Floofer']\n",
    "dog_stage_number = master_df.dog_stage.value_counts().head(6)\n",
    "print('Most Mentioned Dog Stages: Pupper')\n",
    "print(dog_stage_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Rated Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rated_dog = master_df.groupby(['dog_stage']).rating_numerator.sum().sort_values(ascending=False)\n",
    "print('Top Rated Pup')\n",
    "print(top_rated_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_count = master_df.favorite_count\n",
    "retweet_count = master_df.retweet_count\n",
    "N = 4\n",
    "# 0 to 15 point ra\n",
    "colors = np.random.rand(N)\n",
    "plt.scatter(fav_count, retweet_count, c = colors, alpha = 0.5)\n",
    "\n",
    "plt.legend(title = 'Retweets vs Favorites')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Common Dog Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dog_name = master_df.name.value_counts().head(4)\n",
    "common_dog_name = common_dog_name.drop('None')\n",
    "print(common_dog_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the data we rate dogs rates golden retrieve more than any other breed. \n",
    "\n",
    "breed_counts = master_df.breed.value_counts().head(5)\n",
    "labels = ['Golden Retriever', 'Labrador Retriever', 'Pembroke', 'Chihuahua']\n",
    "print(labels)\n",
    "most_breeds = breed_counts.drop(index = 'none')\n",
    "plt.pie(most_breeds, labels = labels)\n",
    "plt.legend(loc='upper left', title = 'Common Dog Breeds')\n",
    "print('Most Common Dog Breeds: ', 'Golden Retriever')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Which UI Source is the most popular? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The owners of the account use the mobile app far more than any other platform of twitter. \n",
    "master_df['source'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
